<!DOCTYPE html>
<html lang="en">
    
<!-- remove after done debugging!!!! -->
<!-- <meta http-equiv="refresh" content="1" > -->
<!-- remove after done debugging!!!! -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Efficient shape mapping through dense touch and vision">
    <meta name="author" content="Sudharshan Suresh, Maria Bauza, Kuan-Ting Yu, Joshua G Mangelson, Alberto Rodriguez, Michael Kaess">

    <title>Efficient shape mapping through dense touch and vision</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="style_tweaks.css" rel="stylesheet">
    <!-- Load logo stylesheets --> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Efficient shape mapping through dense touch and vision</h2>
    <h2> <small> </small></h2>
    <hr>
    <p class="authors">
        <a href="http://www.cs.cmu.edu/~sudhars1/"> Sudharshan Suresh<sup><span style="color:#000000">*</span><span style="color:#1b9e77">1</span></sup></a> &emsp;
        <a href="https://si-lynnn.github.io/"> Zilin Si<sup><span style="color:#000000">*</span><span style="color:#1b9e77">1</span></sup></a> &emsp;
        <a href="https://ece.byu.edu/directory/josh-mangelson"> Joshua G. Mangelson<sup><span style="color:#e7298a">2</span></sup></a> &emsp;
        <a href="http://robotouch.ri.cmu.edu/yuanwz/"> Wenzhen Yuan<sup><span style="color:#1b9e77">1</span></sup></a> &emsp;
        <a href="http://www.cs.cmu.edu/~kaess/"> Michael Kaess<sup><span style="color:#1b9e77">1</span></sup></a>
        <br>
        <sup><span style="color:#1b9e77">1</span></sup>Robotics Institute, Carnegie Mellon University &emsp;  <sup><span style="color:#e7298a">2</span></sup>Brigham Young University

    </p>
    <!-- Preamble: Paper sprite, youtube link, and code link -->
    <div class="btn-group" role="group" aria-label="Top menu">
        <a href="https://arxiv.org/abs/2109.09884" title="Paper" target="_blank">
        <img src="media/shape-map.jpg" alt="Shape map paper" height="100" align="left" style="margin: 0px 30px 0px 0px"/>
        </a>
    
        <a href="https://youtu.be/nFaWtjanQXQ" title="YouTube video" target="_blank">
        <i class="fa fa-youtube-play" style="font-size:100px;color:red; margin: 0px 30px 0px 0px" ></i>
        </a>
    
        <a href="" title="Coming soon!">
        <i class="fa fa-github" style="font-size:100px;color:black; margin: 0px 30px 0px 0px" aria-hidden="true"></i>
        </a>
    </div>
</div>

<div class="container">
    <a href="#intro"></a>
    <div class="row align-items-center">
        <div class="col-md-6 padding-0">
        <img src="media/cover.jpg" alt="Shape map paper" height="300" align="center" style="margin: 0px 0px 0px 0px"/>
        </div>
        <div class="col-md-6 padding-0">
            <video width="60%" autoplay muted loop class="center">
                <source src="media/cover.m4v" type='video/mp4'>
            </video>
        </div>
    </div>
    <div class="row align-items-center">
        <div class="caption center padding-0">
            <span style="color:#e7298a"><b>[left]</b></span> Incremental 3-D shape mapping with a vision-based tactile sensor, GelSight, and an overlooking depth-camera. <span style="color:#e7298a"><b>[right]</b></span> We combine multi-modal sensor measurements into our Gaussian process spatial graph (GP-SG), for efficient incremental mapping. The depth-camera gives a partial noisy estimate of 3-D shape, after which tactile measurements are added sequentially as Gaussian potentials into our GP-SG.
        </div>
    </div>
    <hr>
    <p>
        <em>Knowledge of 3-D object shape is important for robot manipulation, but may not be readily available in unstructured environments. We propose a framework that incrementally reconstructs tabletop 3-D objects from a sequence of tactile images and a noisy depth-map. Our contributions include: <b>(&#8202;i&#8202;)</b> recovering local shape from GelSight images, learned via tactile simulation <b>(&#8202;ii&#8202;)</b> incremental shape mapping through inference on our Gaussian process spatial graph (GP-SG). We demonstrate visuo-tactile mapping in both our simulated and real-world datasets. </em>
    </p>

    <a href="#localshape"></a>
    <div class="section">
        <h2>Local shape from touch</h2>
        <hr>

        <p>
            We train a GelSight-to-depth model with <a href="https://arxiv.org/abs/2109.04027">Taxim</a>, a tactile simulator that mimics intensity distributions from the real sensor. Simulation allows us to scale supervised-learning to a wider range of objects and ground-truth. 
        </p>

        <div class="row align-items-center">
            <div class="row align-items-center">
                <div class="col-md-6 padding-10">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/tactile-flowchart.m4v" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10">
                    <img src="media/tactile-results.jpg" alt="Shape map paper" align="center"  width="550"/>
                    <div class="caption center">
                        Tactile images generated from GelSight interactions in simulated and real settings. Pictured alongside are the height-maps and contact masks output from our learned model. 
                    </div>
                </div>
            </div>
        </div>
    </div>

    <a href="#shapeest"></a>
    <div class="section">
        <h2>Shape estimation on a graph</h2>
        <hr>
        <p>
            A GP is a nonparametric method to learn a continuous function from data, well-suited to model spatial phenomena. We represent the scene as a spatial factor graph, comprising of nodes we optimize for and factors that constrain them. Our optimization goal is to recover the posterior, which represents the SDF and its underlying uncertainty. Implementing the full GP in the graph is costly, as each measurement constrains all query nodes. Motivated by prior work in spatial partitioning, we decompose the GP into local unary factors as a sparse approximation.
        </p>

        <div class="container">
            <div class="row align-items-center">
                <div class="col-md-6 padding-10">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/bunny.m4v" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10">
                    <p>
                        <em>A 2-D illustration of our GP spatial graph (GP-SG), an efficient local approximation to a full GP. Each surface measurement produces a unary factor at query node (within the local radius). This represents a local Gaussian potential for the GP implicit surface. The optimization yields posterior SDF mean + uncertainty. The zero-level set of the SDF gives us the implicit surface.</em>
                    </p>
                </div>
            </div>
        </div>
    </div>
    
    <a href="#sim"></a>
    <div class="section">
        <h2>Experiments: tactile simulation</h2>
        <hr>
        <p>
            We generate 60 GelSight-object interactions uniformly spread across each object in our <a href="" title="Coming soon!" style="font-family:courier;">YCBSight-Sim</a> dataset. We render a depth-map from the perspective of an overlooking camera using <a href="https://github.com/mmatl/pyrender">Pyrender</a>. Finally, zero-mean Gaussian noise is added to tactile point-clouds, sensor poses, and depth-map. <span class="blink_me">Hover over each object to visualize the incremental visuo-tactile mapping</span>. 
        </p>

        <div class="row align-items-center">
            <div class="row align-items-center">
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                        <source src="media/sim_results/bleach_cleanser.m4v" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                        <source src="media/sim_results/wood_block.m4v" type='video/mp4'>
                    </video>
                </div>
            </div>

            <br>

            <div class="row align-items-center">
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                        <source src="media/sim_results/sugar_box.m4v" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                        <source src="media/sim_results/master_chef_can.m4v" type='video/mp4'>
                    </video>
                </div>
            </div>

            <br>

            <div class="row align-items-center">
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                        <source src="media/sim_results/tomato_soup_can.m4v" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                        <source src="media/sim_results/potted_meat_can.m4v" type='video/mp4'>
                    </video>
                </div>
            </div>
        </div>
    </div>

    <a href="#real"></a>
    <div class="section">
        <h2>Experiments: real-world</h2>
        <hr>
        <p>
            We use a UR5e 6-DoF robot arm, mounting the GelSight sensor on a WSG50 parallel gripper. The objects are secured by a mechanical bench vise at a known pose, to ensure they remain static. After capturing the depth-map, we approach each object from a discretized set of angles and heights. We detect contact events by thresholding the tactile images. We collect 40 tactile images of the object's lateral surface, along with the gripper poses via robot kinematics. 
        </p>

        <div class="row align-items-center">
            <div class="row align-items-center">
                <div class="col-md-6 padding-10  ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/021_bleach_cleanser.mp4" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/036_wood_block.mp4" type='video/mp4'>
                    </video>
                </div>
            </div>

            <br>

            <div class="row align-items-center">
                <div class="col-md-6 padding-10 ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/004_sugar_box.mp4" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/002_master_chef_can.mp4" type='video/mp4'>
                    </video>
                </div>
            </div>
            
            <br>
            <div class="row align-items-center">
                <div class="col-md-6 padding-10 ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/005_tomato_soup_can.mp4" type='video/mp4'>
                    </video>
                </div>
                <div class="col-md-6 padding-10 ">
                    <video width="100%" autoplay muted loop class="center">
                        <source src="media/real_tests/010_potted_meat_can.mp4" type='video/mp4'>
                    </video>
                </div>
            </div>
        </div>
    </div>

    <br>
    <p>
        We the mapping results for the <a href="" title="Coming soon!" style="font-family:courier;">YCBSight-Real</a> dataset is similar to that of simulation. <span class="blink_me">Hover over each object to visualize the incremental visuo-tactile mapping</span>. 
    </p>

    <div class="row align-items-center">
        <div class="row align-items-center">
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                    <source src="media/real_results/bleach_cleanser.m4v" type='video/mp4'>
                </video>
            </div>
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                    <source src="media/real_results/wood_block.m4v" type='video/mp4'>
                </video>
            </div>
        </div>

        <br>

        <div class="row align-items-center">
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                    <source src="media/real_results/sugar_box.m4v" type='video/mp4'>
                </video>
            </div>
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                    <source src="media/real_results/master_chef_can.m4v" type='video/mp4'>
                </video>
            </div>
        </div>

        <br>
        
        <div class="row align-items-center">
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video center">
                    <source src="media/real_results/tomato_soup_can.m4v" type='video/mp4'>
                </video>
            </div>
            <div class="col-md-6 padding-10 ">
                <video width="100%" onmouseover="this.play()" onmouseout="this.pause()" muted loop class="hover-video  center">
                    <source src="media/real_results/potted_meat_can.m4v" type='video/mp4'>
                </video>
            </div>
        </div>
    </div>
    
</div>

    <a href="#bib"></a>
    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <pre>
            @misc{suresh2021efficient,
                  title={Efficient shape mapping through dense touch and vision}, 
                  author={Sudharshan Suresh and Zilin Si and Joshua G. Mangelson and Wenzhen Yuan and Michael Kaess},
                  year={2021},
                  eprint={2109.09884},
                  archivePrefix={arXiv},
                  primaryClass={cs.RO}
                 }
        </pre>
    </div>

    <footer>
        Website template courtesy of <a href="http://web.stanford.edu/~sitzmann/">Vincent Sitzmann</a>.
    </footer>
    <p>&nbsp;</p> 
</div>


<!-- https://getbootstrap.com/docs/4.5/getting-started/introduction/ -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>